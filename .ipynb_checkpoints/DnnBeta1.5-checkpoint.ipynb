{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16b1853f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID    lineage\n",
      "0     \"ON414702\"  \"BA.2.31\"\n",
      "1     \"ON056475\"  \"BA.2.31\"\n",
      "2     \"ON203732\"  \"BA.2.31\"\n",
      "3     \"OW275801\"  \"BA.2.31\"\n",
      "4     \"ON914730\"  \"BA.2.31\"\n",
      "...          ...        ...\n",
      "4995  \"OM122217\"  \"BA.1.17\"\n",
      "4996  \"OV662626\"  \"BA.1.17\"\n",
      "4997  \"OM200680\"  \"BA.1.17\"\n",
      "4998  \"OW742696\"  \"BA.1.17\"\n",
      "4999  \"OW120613\"  \"BA.1.17\"\n",
      "\n",
      "[5000 rows x 2 columns]\n",
      "              ID                                       Enc_Sequence    lineage\n",
      "0     \"FR990446\"  0000010000000101000001010000011111110110001101...  \"B.1.258\"\n",
      "1     \"FR991388\"  1010111111001100010111110101010010101100000100...  \"B.1.258\"\n",
      "2     \"FR991439\"  0000010100000111111101100011011101111110110010...  \"B.1.258\"\n",
      "3     \"HG994296\"  0000000000000000000000000000000000000001010010...  \"B.1.258\"\n",
      "4     \"HG994312\"  0000000000000000000000000000000000000000000000...  \"B.1.258\"\n",
      "...          ...                                                ...        ...\n",
      "4995  \"OX273314\"  0000000000000000000000000000000000000000000000...   \"BA.5.1\"\n",
      "4996  \"OX273355\"  0000000000000000000000000000000000000000000000...   \"BA.5.1\"\n",
      "4997  \"OX273527\"  0000000000000000000000000000000000000000000000...   \"BA.5.1\"\n",
      "4998  \"OX273539\"  0000000000000000000000000000000000000000000000...   \"BA.5.1\"\n",
      "4999  \"OX273975\"  0000000000000000000000000000000000000000000000...   \"BA.5.1\"\n",
      "\n",
      "[5000 rows x 3 columns]\n",
      "ViralSequencesDataset\n",
      "Dataset size: 5000\n",
      "Max length: 59814\n",
      "\n",
      "Data:\n",
      "           ID                                       Enc_Sequence    lineage\n",
      "0  \"FR990446\"  0000010000000101000001010000011111110110001101...  \"B.1.258\"\n",
      "1  \"FR991388\"  1010111111001100010111110101010010101100000100...  \"B.1.258\"\n",
      "2  \"FR991439\"  0000010100000111111101100011011101111110110010...  \"B.1.258\"\n",
      "3  \"HG994296\"  0000000000000000000000000000000000000001010010...  \"B.1.258\"\n",
      "4  \"HG994312\"  0000000000000000000000000000000000000000000000...  \"B.1.258\"\n",
      "Using device: cuda\n",
      "Epoch [1/5] - Batch [10/63] - Loss: 2.0084 - Accuracy: 33.91%\n",
      "Epoch [1/5] - Batch [20/63] - Loss: 1.5292 - Accuracy: 43.91%\n",
      "Epoch [1/5] - Batch [30/63] - Loss: 1.2468 - Accuracy: 59.38%\n",
      "Epoch [1/5] - Batch [40/63] - Loss: 1.2167 - Accuracy: 62.34%\n",
      "Epoch [1/5] - Batch [50/63] - Loss: 1.1224 - Accuracy: 62.97%\n",
      "Epoch [1/5] - Batch [60/63] - Loss: 1.0386 - Accuracy: 64.53%\n",
      "Epoch [2/5] - Batch [10/63] - Loss: 0.9245 - Accuracy: 68.28%\n",
      "Epoch [2/5] - Batch [20/63] - Loss: 0.8893 - Accuracy: 69.22%\n",
      "Epoch [2/5] - Batch [30/63] - Loss: 0.8406 - Accuracy: 69.53%\n",
      "Epoch [2/5] - Batch [40/63] - Loss: 0.8885 - Accuracy: 69.84%\n",
      "Epoch [2/5] - Batch [50/63] - Loss: 0.8270 - Accuracy: 71.56%\n",
      "Epoch [2/5] - Batch [60/63] - Loss: 0.8055 - Accuracy: 72.19%\n",
      "Epoch [3/5] - Batch [10/63] - Loss: 0.7695 - Accuracy: 73.28%\n",
      "Epoch [3/5] - Batch [20/63] - Loss: 0.6910 - Accuracy: 73.75%\n",
      "Epoch [3/5] - Batch [30/63] - Loss: 0.6990 - Accuracy: 74.69%\n",
      "Epoch [3/5] - Batch [40/63] - Loss: 0.6574 - Accuracy: 77.81%\n",
      "Epoch [3/5] - Batch [50/63] - Loss: 0.7186 - Accuracy: 75.62%\n",
      "Epoch [3/5] - Batch [60/63] - Loss: 0.6247 - Accuracy: 76.88%\n",
      "Epoch [4/5] - Batch [10/63] - Loss: 0.6228 - Accuracy: 77.50%\n",
      "Epoch [4/5] - Batch [20/63] - Loss: 0.6001 - Accuracy: 77.97%\n",
      "Epoch [4/5] - Batch [30/63] - Loss: 0.5743 - Accuracy: 79.06%\n",
      "Epoch [4/5] - Batch [40/63] - Loss: 0.5707 - Accuracy: 79.84%\n",
      "Epoch [4/5] - Batch [50/63] - Loss: 0.6151 - Accuracy: 76.56%\n",
      "Epoch [4/5] - Batch [60/63] - Loss: 0.6207 - Accuracy: 77.50%\n",
      "Epoch [5/5] - Batch [10/63] - Loss: 0.5297 - Accuracy: 80.47%\n",
      "Epoch [5/5] - Batch [20/63] - Loss: 0.5178 - Accuracy: 82.34%\n",
      "Epoch [5/5] - Batch [30/63] - Loss: 0.5907 - Accuracy: 78.75%\n",
      "Epoch [5/5] - Batch [40/63] - Loss: 0.5608 - Accuracy: 81.25%\n",
      "Epoch [5/5] - Batch [50/63] - Loss: 0.5583 - Accuracy: 78.75%\n",
      "Epoch [5/5] - Batch [60/63] - Loss: 0.4897 - Accuracy: 84.06%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "from torch.utils.data import random_split\n",
    "# Step 1: Load the data\n",
    "lineage_file = \"./dataset1.csv\"\n",
    "text_files_folder = \"./text_files\"\n",
    "\n",
    "# Step 2: Load all the text files to converted_df\n",
    "converted_data = []\n",
    "for file_path in os.listdir(text_files_folder):\n",
    "    file_name = os.path.splitext(file_path)[0]\n",
    "    with open(os.path.join(text_files_folder, file_path), \"r\") as file:\n",
    "        content = file.read().strip()\n",
    "        converted_data.append(['\"' + file_name + '\"', content])\n",
    "\n",
    "converted_df = pd.DataFrame(converted_data, columns=[\"ID\", \"Enc_Sequence\"])\n",
    "max_length = converted_df[\"Enc_Sequence\"].str.len().max()\n",
    "####################################################################################\n",
    "\n",
    "# Step 3: Load lineage file as DataFrame\n",
    "lineage_df = pd.read_csv(lineage_file)\n",
    "print(lineage_df)\n",
    "merged_df = pd.merge(converted_df, lineage_df, on=\"ID\", how=\"left\")\n",
    "converted_df[\"lineage\"] = merged_df[\"lineage\"]\n",
    "\n",
    "print(converted_df)\n",
    "\n",
    "\n",
    "lineages = lineage_df[\"lineage\"].unique()\n",
    "num_classes = len(lineages)\n",
    "lineage_to_id = {lineage: i for i, lineage in enumerate(lineages)}\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "# Step 4: Prepare the data for training\n",
    "class ViralSequencesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, converted_df, max_length, lineage_to_id):\n",
    "        self.data = converted_df\n",
    "        self.max_length = max_length\n",
    "        self.lineage_to_id = lineage_to_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sequence = self.data.iloc[index][\"Enc_Sequence\"]\n",
    "        enc_sequence = np.array(list(sequence), dtype=np.uint8)\n",
    "        enc_sequence = enc_sequence.reshape(-1)  # Remove extra dimensions\n",
    "\n",
    "        # Pad the sequence with zeros\n",
    "        padded_sequence = nn.functional.pad(torch.tensor(enc_sequence), pad=(0, self.max_length - len(enc_sequence)))\n",
    "\n",
    "        lineage = self.data.iloc[index][\"lineage\"]\n",
    "        lineage_id = self.lineage_to_id[lineage]\n",
    "\n",
    "        return padded_sequence, lineage_id, len(enc_sequence)  # Return sequence length\n",
    "    \n",
    "    def __str__(self):\n",
    "        dataset_info = f\"ViralSequencesDataset\\nDataset size: {len(self)}\\nMax length: {self.max_length}\"\n",
    "        data_info = f\"Data:\\n{self.data.head()}\"\n",
    "        return f\"{dataset_info}\\n\\n{data_info}\"\n",
    "\n",
    "\n",
    "# dataset = ViralSequencesDataset(output_file, max_length)\n",
    "dataset = ViralSequencesDataset(converted_df, max_length, lineage_to_id)\n",
    "print(dataset)\n",
    "# Set the batch size and split ratio\n",
    "batch_size = 64\n",
    "train_ratio = 0.8\n",
    "\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "#####################################################################################\n",
    "\n",
    "# Step 5: Define the model architecture\n",
    "class LineageClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LineageClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, length):\n",
    "        out = self.fc1(x.float())\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "#####################################################################################\n",
    "\n",
    "# Step 6: Train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Set the sequence length\n",
    "sequence_length = max_length\n",
    "\n",
    "# Set the number of output classes\n",
    "num_classes = 10  # Change this to the appropriate number of classes\n",
    "\n",
    "Hidden_size=512\n",
    "\n",
    "# Initialize the model\n",
    "model = LineageClassifier(input_size=sequence_length, hidden_size=Hidden_size, num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Set the number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Initialize variables for early stopping\n",
    "best_loss = float('inf')\n",
    "patience = 3\n",
    "counter = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets, lengths) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, lengths)  # Pass lengths to the model\n",
    "\n",
    "        targets = targets.view(-1)\n",
    "        outputs = outputs.view(-1, num_classes)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "        if batch_idx % 10 == 9:\n",
    "            batch_loss = running_loss / 10\n",
    "            accuracy = 100 * correct_predictions / (10 * len(inputs))\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] - Batch [{batch_idx+1}/{len(train_loader)}] - Loss: {batch_loss:.4f} - Accuracy: {accuracy:.2f}%\")\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "# Step 7: Save the trained model\n",
    "torch.save(model.state_dict(), \"./lineage_classifier.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9495eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 76.30%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#####################\n",
    "# WORKING TEST\n",
    "#####################\n",
    "# Step 8: Test the model\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, lengths in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs, lengths)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total_samples += targets.size(0)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct_predictions / total_samples\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Call the test function\n",
    "test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a44ef475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8), tensor([1, 1, 6, 7, 9, 2, 0, 5, 6, 0, 6, 0, 1, 1, 3, 2, 4, 6, 4, 1, 6, 6, 0, 6,\n",
      "        9, 8, 7, 3, 9, 4, 5, 6, 9, 2, 6, 3, 1, 3, 8, 9, 2, 9, 7, 9, 8, 4, 3, 1,\n",
      "        0, 5, 9, 8, 2, 1, 6, 3, 0, 9, 0, 4, 2, 0, 0, 9]), tensor([59780, 59780, 59740, 59416, 59654, 59416, 59326, 59538, 59688, 58596,\n",
      "        59436, 59620, 59658, 59780, 59780, 59624, 59690, 59436, 58094, 59598,\n",
      "        59688, 59688, 59752, 59436, 59746, 59794, 59792, 59780, 59540, 59638,\n",
      "        58980, 59688, 59734, 59564, 59688, 59780, 59768, 59780, 59770, 59746,\n",
      "        59690, 59242, 59554, 59740, 59794, 59262, 59780, 59592, 59700, 59534,\n",
      "        59638, 59798, 59700, 59540, 57092, 59292, 59370, 59554, 59448, 59062,\n",
      "        59734, 59448, 59448, 59746])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_loader):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(inputs)\n\u001b[1;32m---> 21\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     22\u001b[0m     targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "\n",
    "#####################\n",
    "# NOT WORKING RIGHT NOW\n",
    "#####################\n",
    "# # Load the saved model state dict\n",
    "# model = LineageClassifier(input_size=sequence_length, hidden_size=Hidden_size, num_classes=num_classes)\n",
    "# model.load_state_dict(torch.load(\"./lineage_classifier.pth\"))\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# # Create the test DataLoader\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Define evaluation metrics\n",
    "# test_loss = 0.0\n",
    "# correct_predictions = 0\n",
    "# total_predictions = 0\n",
    "\n",
    "# # Perform model evaluation\n",
    "# with torch.no_grad():\n",
    "#     for batch_idx, inputs in enumerate(test_loader):\n",
    "#         print(inputs)\n",
    "#         inputs = torch.tensor(inputs).to(device)\n",
    "#         targets = torch.ones(inputs.size(0)).long().to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(inputs)\n",
    "\n",
    "#         # Compute the loss\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         test_loss += loss.item()\n",
    "\n",
    "#         # Calculate accuracy\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total_predictions += targets.size(0)\n",
    "#         correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "# # Calculate average test loss and accuracy\n",
    "# avg_test_loss = test_loss / len(test_loader)\n",
    "# test_accuracy = 100.0 * correct_predictions / total_predictions\n",
    "\n",
    "# # Print the test results\n",
    "# print(\"Test Loss: {:.4f}\".format(avg_test_loss))\n",
    "# print(\"Test Accuracy: {:.2f}%\".format(test_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
